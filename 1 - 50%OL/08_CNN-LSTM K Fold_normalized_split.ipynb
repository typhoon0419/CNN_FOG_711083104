{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, ConvLSTM2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,roc_auc_score,recall_score,precision_score\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + \"/dataset/total_concentrated.csv\"\n",
    "# features = [\"A_F\", \"A_V\", \"A_L\", \"L_F\", \"L_T\", \"L_L\", \"T_F\", \"T_V\", \"T_L\"]\n",
    "\n",
    "dataset = pd.read_csv(data_path)\n",
    "time = list(dataset['time'])\n",
    "dataframe = dataset[[\"A_F\", \"A_V\", \"A_L\", \"L_F\", \"L_V\", \"L_L\", \"T_F\", \"T_V\", \"T_L\"]].values\n",
    "dataset = dataset[[\"A_F\", \"A_V\", \"A_L\", \"L_F\", \"L_V\", \"L_L\", \"T_F\", \"T_V\", \"T_L\", \"Action\"]].values\n",
    "\n",
    "window_length = int(1*64)\n",
    "total_windows = int((len(dataset))/window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = (dataframe-dataframe.mean())/dataframe.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認每段資料能不能整除64/2, 並輸出不能整除的個數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "indices = time\n",
    "groups = []\n",
    "group_count = 0\n",
    "temp = []\n",
    "lenOfGroup = []\n",
    "length_count = 0\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    if i == (len(indices) - 1):\n",
    "        temp.append(indices[i])\n",
    "        length_count = length_count + 1\n",
    "\n",
    "        groups.append(temp)\n",
    "        lenOfGroup.append(length_count)\n",
    "        length_count = 0\n",
    "        temp = []\n",
    "        break\n",
    "    temp.append(indices[i])\n",
    "    length_count = length_count + 1\n",
    "    if (indices[i+1] - 20 > indices[i]):\n",
    "        group_count = group_count + 1\n",
    "\n",
    "        lenOfGroup.append(length_count)\n",
    "        length_count = 0\n",
    "\n",
    "        groups.append(temp)\n",
    "        temp = []\n",
    "\n",
    "del temp, indices, group_count, length_count, i\n",
    "\n",
    "countOfUndivisible = 0\n",
    "total_windows_with_overlap_train = 0\n",
    "\n",
    "start_index = 0\n",
    "\n",
    "stop_Indexs = []\n",
    "stop_Index = -window_length\n",
    "\n",
    "\n",
    "for lengths in lenOfGroup:\n",
    "    stop_Index = stop_Index + lengths\n",
    "    stop_Indexs.append(stop_Index)\n",
    "    total_windows_with_overlap_train = total_windows_with_overlap_train + int(float(lengths/window_length)*2 -1)\n",
    "    \n",
    "    if lengths % (window_length/2) != 0:\n",
    "        countOfUndivisible = countOfUndivisible + 1\n",
    "        print(lengths)\n",
    "\n",
    "print(countOfUndivisible)\n",
    "del countOfUndivisible, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((total_windows_with_overlap_train, window_length*9))\n",
    "y = np.empty((total_windows_with_overlap_train, 1))\n",
    "\n",
    "stop_Index = 0\n",
    "window_count = 0\n",
    "\n",
    "for window in range(total_windows_with_overlap_train):\n",
    "    for i in range(window_length):\n",
    "        if i == 0:\n",
    "            y[window] = dataset[int(window_count*window_length), 9]\n",
    "        \n",
    "        if int(window_count*window_length)<len(dataset)-window_length-1:\n",
    "            for data in range(9):\n",
    "               X[window, i*9 + data] = dataframe[int(window_count*window_length) + i, data]\n",
    "        if stop_Index < len(stop_Indexs):\n",
    "            if int(window_count*window_length) == stop_Indexs[stop_Index]:\n",
    "                window_count = window_count + 0.5\n",
    "                stop_Index = stop_Index + 1\n",
    "        if window == total_windows_with_overlap_train-1:\n",
    "            X[window, i*9 + data] = dataframe[int((window_count-0.5)*window_length) + i, data]\n",
    "    window_count = window_count + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "class_weight = {0:(1/counts[0])*len(y)/2, 1:(1/counts[1])*len(y)/2, 2:(1/counts[2])*len(y)/2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle = True, random_state=42)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_3Darray(array):\n",
    "    arr_3d = np.empty((len(array), window_length, 9))\n",
    "\n",
    "\n",
    "    arr_3d = np.reshape(array, (len(array), window_length, 9))\n",
    "    return arr_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_in_fold = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_outside_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Fold #0\n",
      "Loss: 0.316% Accuracy: 87.777% \n",
      "precision: 86.905% recall: 53.808% F1 score: 66.464%\n",
      "==> Fold #1\n",
      "Loss: 0.373% Accuracy: 85.563% \n",
      "precision: 90.873% recall: 47.808% F1 score: 62.654%\n",
      "==> Fold #2\n",
      "Loss: 0.265% Accuracy: 90.594% \n",
      "precision: 89.286% recall: 60.322% F1 score: 72.000%\n",
      "==> Fold #3\n",
      "Loss: 0.294% Accuracy: 88.475% \n",
      "precision: 82.143% recall: 54.762% F1 score: 65.714%\n",
      "==> Fold #4\n",
      "Loss: 0.592% Accuracy: 73.679% \n",
      "precision: 94.048% recall: 33.193% F1 score: 49.068%\n",
      "==> Fold #5\n",
      "Loss: 0.272% Accuracy: 89.683% \n",
      "precision: 84.524% recall: 58.197% F1 score: 68.932%\n",
      "==> Fold #6\n",
      "Loss: 0.368% Accuracy: 86.059% \n",
      "precision: 88.845% recall: 49.556% F1 score: 63.623%\n",
      "==> Fold #7\n",
      "Loss: 0.315% Accuracy: 88.374% \n",
      "precision: 86.454% recall: 54.937% F1 score: 67.183%\n",
      "==> Fold #8\n",
      "Loss: 0.348% Accuracy: 87.116% \n",
      "precision: 84.462% recall: 51.084% F1 score: 63.664%\n",
      "==> Fold #9\n",
      "Loss: 0.335% Accuracy: 87.871% \n",
      "precision: 86.056% recall: 52.555% F1 score: 65.257%\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    print(\"==> Fold #%d\" % i)\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    X_train = to_3Darray(X_train)\n",
    "    y_train = to_categorical(y_train)\n",
    "\n",
    "    X_val = to_3Darray(X_val)\n",
    "    y_val = to_categorical(y_val)\n",
    "\n",
    "\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 50, 64\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    n_steps, n_length = 2, 32\n",
    "    X_train = X_train.reshape((X_train.shape[0], n_steps, n_length, n_features))\n",
    "    X_val = X_val.reshape((X_val.shape[0], n_steps, n_length, n_features))\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "                            input_shape=(None, n_length, n_features)))\n",
    "    model.add(TimeDistributed(\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    hunderdOutput = Dense(100, activation='relu')\n",
    "    model.add(hunderdOutput)  # feature\n",
    "    # 試著輸出長度為100的向量(feature) 並絳維 看他的分布有無分開\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) #可能可以調weighting\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, class_weight = class_weight)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(X_val, y_val, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "\n",
    "    y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "    y_val = np.argmax(y_val, axis=1)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    confus = confusion_matrix(y_val, y_pred, labels=None, sample_weight=None)\n",
    "    tp = confus[1][1]\n",
    "    tn = confus[0][0] + confus[0][2] + confus[2][0] + confus[2][2]\n",
    "    fp = confus[1][0] + confus[1][2]\n",
    "    fn = confus[0][1] + confus[2][1]\n",
    "\n",
    "    precision = (tp/(tp + fp))*100\n",
    "    recall =  (tp / (tp + fn))*100   #sensitivity\n",
    "    F1_score = ((2*tp) / (2*tp + fp + fn))*100\n",
    "\n",
    "    score = accuracy\n",
    "    losses.append(loss)\n",
    "    \n",
    "    score = score * 100.0\n",
    "    scores_in_fold.append(score)\n",
    "    \n",
    "    print('Loss: %.3f%% Accuracy: %.3f%% ' % (loss, score))\n",
    "    print('precision: %.3f%% recall: %.3f%% F1 score: %.3f%%' % (precision, recall, F1_score))\n",
    "    # print(confus)\n",
    "\n",
    "\n",
    "    \n",
    "    '''score = evaluate_model(X_train, y_train, X_val, y_val)\n",
    "    score = score * 100.0\n",
    "    print(score)\n",
    "    scores.append(score)'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerIndex = 7\n",
    "func = k.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)\n",
    "layerOutput = func([X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(layerOutput)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "y_val = pd.DataFrame(data = y_val, columns=['targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = pd.concat([principalDf, y_val], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure(figsize = (8,8))\n",
    "# ax = fig.add_subplot(1,1,1) \n",
    "# ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "# ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "# ax.set_title('2 component PCA', fontsize = 20)\n",
    "# targets = [0, 1, 2]\n",
    "# colors = ['r', 'g', 'b']\n",
    "# for target, color in zip(targets,colors):\n",
    "#     indicesToKeep = finalDF[2] == target\n",
    "#     ax.scatter(finalDF.loc[indicesToKeep, 0]\n",
    "#                , finalDF.loc[indicesToKeep, 1]\n",
    "#                , c = color\n",
    "#                , s = 50)\n",
    "# ax.legend(targets)\n",
    "# ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.519% (+/-4.513)\n"
     ]
    }
   ],
   "source": [
    "m, s = np.mean(scores_in_fold), np.std(scores_in_fold)\n",
    "print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = to_3Darray(X_test)\n",
    "#y_test = to_categorical(y_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], n_steps, n_length, n_features))\n",
    "\n",
    "\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "confus = confusion_matrix(y_test, y_pred, labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3881  415   13]\n",
      " [  70  533    8]\n",
      " [  11   35    3]]\n"
     ]
    }
   ],
   "source": [
    "print(confus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.891% \n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy\n",
    "print('Accuracy: %.3f%% ' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('HighHeel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "959bdcf6eeb887451bcffa363d74cc943bc68c54a0b2bd40671995429a0a3362"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
