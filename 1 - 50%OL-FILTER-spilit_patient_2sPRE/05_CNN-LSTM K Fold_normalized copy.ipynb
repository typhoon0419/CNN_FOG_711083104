{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, ConvLSTM2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + \"/dataset/total_concentrated.csv\"\n",
    "# features = [\"A_F\", \"A_V\", \"A_L\", \"L_F\", \"L_T\", \"L_L\", \"T_F\", \"T_V\", \"T_L\"]\n",
    "\n",
    "dataset = pd.read_csv(data_path)\n",
    "time = list(dataset['time'])\n",
    "dataframe = dataset[[\"A_F\", \"A_V\", \"A_L\", \"L_F\", \"L_V\", \"L_L\", \"T_F\", \"T_V\", \"T_L\"]].values\n",
    "dataset = dataset[[\"A_F\", \"A_V\", \"A_L\", \"L_F\", \"L_V\", \"L_L\", \"T_F\", \"T_V\", \"T_L\", \"Action\"]].values\n",
    "\n",
    "window_length = int(1*64)\n",
    "total_windows = int((len(dataset))/window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = (dataframe-dataframe.mean())/dataframe.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 50, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "    n_steps, n_length = 4, 16\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), \n",
    "                              input_shape=(None, n_length, n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = np.empty((total_windows, window_length, 9))\\ny = np.empty((total_windows, 1))\\nj = 0\\n\\nwindow_count = 0\\nfor items in range(total_windows):\\n    for i in range(window_length):\\n        if i == 0:\\n            y[j] = dataset[int(window_count*window_length), 9]\\n            j = j + 1\\n        for data in range(9):\\n            X[items, i, data] = dataset[int(window_count*window_length)+i, data]\\n    window_count = window_count+1\\n\\ndel window_count, i, j, items, data\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X = np.empty((total_windows, window_length, 9))\n",
    "y = np.empty((total_windows, 1))\n",
    "j = 0\n",
    "\n",
    "window_count = 0\n",
    "for items in range(total_windows):\n",
    "    for i in range(window_length):\n",
    "        if i == 0:\n",
    "            y[j] = dataset[int(window_count*window_length), 9]\n",
    "            j = j + 1\n",
    "        for data in range(9):\n",
    "            X[items, i, data] = dataset[int(window_count*window_length)+i, data]\n",
    "    window_count = window_count+1\n",
    "\n",
    "del window_count, i, j, items, data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = time\n",
    "groups = []\n",
    "group_count = 0\n",
    "temp = []\n",
    "lenOfGroup = []\n",
    "length_count = 0\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    if i == (len(indices) - 1):\n",
    "        temp.append(indices[i])\n",
    "        length_count = length_count + 1\n",
    "\n",
    "        groups.append(temp)\n",
    "        lenOfGroup.append(length_count)\n",
    "        length_count = 0\n",
    "        temp = []\n",
    "        break\n",
    "    temp.append(indices[i])\n",
    "    length_count = length_count + 1\n",
    "    if (indices[i+1] - 20 > indices[i]):\n",
    "        group_count = group_count + 1\n",
    "\n",
    "        lenOfGroup.append(length_count)\n",
    "        length_count = 0\n",
    "\n",
    "        groups.append(temp)\n",
    "        temp = []\n",
    "\n",
    "del temp, indices, group_count, length_count, i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認每段資料能不能整除64/2, 並輸出不能整除的個數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "countOfUndivisible = 0\n",
    "total_windows_with_overlap = 0\n",
    "\n",
    "start_index = 0\n",
    "\n",
    "stop_Indexs = []\n",
    "stop_Index = -window_length\n",
    "\n",
    "\n",
    "for lengths in lenOfGroup:\n",
    "    stop_Index = stop_Index + lengths\n",
    "    stop_Indexs.append(stop_Index)\n",
    "    total_windows_with_overlap = total_windows_with_overlap + int(lengths/window_length*2 -1)\n",
    "    \n",
    "    if lengths % (window_length/2) != 0:\n",
    "        countOfUndivisible = countOfUndivisible + 1\n",
    "        print(lengths)\n",
    "\n",
    "print(countOfUndivisible)\n",
    "del countOfUndivisible, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((total_windows_with_overlap, window_length*9))\n",
    "y = np.empty((total_windows_with_overlap, 1))\n",
    "\n",
    "stop_Index = 0\n",
    "window_count = 0\n",
    "\n",
    "for window in range(total_windows_with_overlap):\n",
    "    for i in range(window_length):\n",
    "        if i == 0:\n",
    "            y[window] = dataset[int(window_count*window_length), 9]\n",
    "        \n",
    "        if int(window_count*window_length)<len(dataset)-window_length-1:\n",
    "            for data in range(9):\n",
    "               X[window, i*9 + data] = dataframe[int(window_count*window_length) + i, data]\n",
    "        if stop_Index < len(stop_Indexs):\n",
    "            if int(window_count*window_length) == stop_Indexs[stop_Index]:\n",
    "                window_count = window_count + 0.5\n",
    "                stop_Index = stop_Index + 1\n",
    "    window_count = window_count + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle = True, random_state=42)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_3Darray(array):\n",
    "    arr_3d = np.empty((len(array), window_length, 9))\n",
    "\n",
    "\n",
    "    arr_3d = np.reshape(array, (len(array), window_length, 9))\n",
    "    return arr_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(trainX, trainy, testX, testy, repeats):\n",
    "\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    \n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Fold #0\n",
      ">#1: 93.560\n",
      "Accuracy: 93.560% (+/-0.000)\n",
      "==> Fold #1\n",
      ">#1: 94.486\n",
      "Accuracy: 94.486% (+/-0.000)\n",
      "==> Fold #2\n",
      ">#1: 94.344\n",
      "Accuracy: 94.344% (+/-0.000)\n",
      "==> Fold #3\n",
      ">#1: 94.002\n",
      "Accuracy: 94.002% (+/-0.000)\n",
      "==> Fold #4\n",
      ">#1: 94.042\n",
      "Accuracy: 94.042% (+/-0.000)\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    print(\"==> Fold #%d\" % i)\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    X_train = to_3Darray(X_train)\n",
    "    y_train = to_categorical(y_train)\n",
    "\n",
    "    X_val = to_3Darray(X_val)\n",
    "    y_val = to_categorical(y_val)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    score=run_experiment(X_train, y_train, X_val, y_val, repeats=1)\n",
    "    scores.append(score)\n",
    "    '''score = evaluate_model(X_train, y_train, X_val, y_val)\n",
    "    score = score * 100.0\n",
    "    print(score)\n",
    "    scores.append(score)'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.087% (+/-0.320)\n"
     ]
    }
   ],
   "source": [
    "m, s = np.mean(scores), np.std(scores)\n",
    "print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdb0dce53ee342b4df2ec29da00f64db1b0b5ad6c6a758debba5208518f3513a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('HighHeel': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
