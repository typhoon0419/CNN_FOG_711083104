{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + \"/dataset/original_data\"\n",
    "first_processing_path = os.getcwd() +\"/dataset/raw_labelled\"\n",
    "second_processing_path = os.getcwd() +\"/dataset/windows\"\n",
    "final_dataset_path = os.getcwd() +\"/dataset\"\n",
    "test_patients = [\"S09\"]\n",
    "\n",
    "window_length = 1*64\n",
    "b, a = butter(5, 16/window_length, btype='lowpass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "people[] -> 存所有在資料夾中的txt檔\n",
    "\n",
    "'''\n",
    "people = [] #S01R01.txt~S10R01.txt\n",
    "\n",
    "for person in os.listdir(data_path):\n",
    "    if '.txt' in person:\n",
    "        people.append(person)\n",
    "\n",
    "\n",
    "del person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_prefog(dataset, window_length):\n",
    "# def label_prefog(dataset, window_length = 1):\n",
    "    # Drop all the rows for which Action is 0 or the rows which are not part of the experiment\n",
    "    # 將所有的Action==0(未實驗)的部分刪除，並不回傳任何值(implace的部分)\n",
    "    dataset.drop(index = list(dataset[dataset['Action'] == 0].index),\n",
    "                 inplace = True)\n",
    "\n",
    "    time = dataset[\"time\"].values\n",
    "    dataset.drop([\"time\"], axis=1, inplace=True)\n",
    "    time = (time-time.min())/1000\n",
    "    temp = pd.Series(time)\n",
    "    dataset[\"time\"] = temp.values\n",
    "    dataset = dataset[['time',\n",
    "                                'A_F', 'A_V', 'A_L',\n",
    "                                'L_F', 'L_V', 'L_L',\n",
    "                                'T_F', 'T_V', 'T_L',\n",
    "                                'Action']]\n",
    "    # window_length = int(64*window_length)\n",
    "    #print(window_length)\n",
    "    fog_index = []\n",
    "    for i in dataset.index:\n",
    "        if dataset.loc[i, 'Action'] == 2: # 取index和'Action'對應到的資料\n",
    "            fog_index.append(i) # 將發生fog的index存入fog_index這個array\n",
    "    fog_index\n",
    "    \n",
    "    # print(fog_index)\n",
    "    \n",
    "    start_indices = []\n",
    "    for i in fog_index:\n",
    "        if (dataset.loc[i-1, 'Action'] != dataset.loc[i, 'Action']):\n",
    "            start_indices.append(i) # 將發生fog之前的index存入start_indices這個array\n",
    "    \n",
    "    # print(start_indices)\n",
    "\n",
    "    prefog = []\n",
    "    for start in start_indices:\n",
    "        prefog_start = [x for x in range(start-window_length, start)] # prefog_start把FOG之前的windows標記起來\n",
    "        prefog.append(prefog_start)\n",
    "        \n",
    "    # print(prefog) # 2D array\n",
    "\n",
    "    prefog = [item for sublist in prefog for item in sublist] # 把[][]轉換成[]\n",
    "\n",
    "    # print(prefog) # 1D array\n",
    "\n",
    "    for i in prefog:\n",
    "        if dataset.loc[i, \"Action\"] == 2:\n",
    "            print (i)\n",
    "        dataset.loc[i,'Action'] = 3 # 把紀錄在Pre-fog的index action 記錄成3\n",
    "    dataset['Action'] = dataset['Action'] - 1 # 所有action編號-1 使0=walk 1=fog 2= pre-fog\n",
    "\n",
    "    dataset['A_F'] = lfilter(b, a, dataset['A_F'])\n",
    "    dataset['A_V'] = lfilter(b, a, dataset['A_V'])\n",
    "    dataset['A_L'] = lfilter(b, a, dataset['A_L'])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01\n",
      "S01R01.txt  is read\tAdding S01R01.txt to dataset\tS01R01.txt is labelled\n",
      "\n",
      "S01\n",
      "S01R02.txt  is read\tAdding S01R02.txt to dataset\tS01R02.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R01.txt  is read\tAdding S02R01.txt to dataset\tS02R01.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R02.txt  is read\tAdding S02R02.txt to dataset\tS02R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R01.txt  is read\tAdding S03R01.txt to dataset\tS03R01.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R02.txt  is read\tAdding S03R02.txt to dataset\t22456\n",
      "S03R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R03.txt  is read\t\n",
      "S04\n",
      "S04R01.txt  is read\t\n",
      "S05\n",
      "S05R01.txt  is read\tAdding S05R01.txt to dataset\tS05R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R02.txt  is read\tAdding S05R02.txt to dataset\tS05R02.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R01.txt  is read\tAdding S06R01.txt to dataset\tS06R01.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R02.txt  is read\t\n",
      "S07\n",
      "S07R01.txt  is read\tAdding S07R01.txt to dataset\tS07R01.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R02.txt  is read\tAdding S07R02.txt to dataset\tS07R02.txt is labelled\n",
      "\n",
      "S08\n",
      "S08R01.txt  is read\tAdding S08R01.txt to dataset\tS08R01.txt is labelled\n",
      "\n",
      "S09\n",
      "S09R01.txt  is read\tAdding S09R01.txt to dataset\tS09R01.txt is labelled\n",
      "\n",
      "S10\n",
      "S10R01.txt  is read\t\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame()\n",
    "last_name = '' # 紀錄哪個是最終的病患\n",
    "patients = [] # 病患ID list\n",
    "i = 1\n",
    "for person in people:\n",
    "    name = person.split('R')[0]\n",
    "\n",
    "    if name != last_name:\n",
    "        dataset = dataset.drop(index=dataset.index)\n",
    "        patients.append(name)\n",
    "    last_name = name\n",
    "    print(name)\n",
    "\n",
    "    file = data_path + \"\\\\\" + person\n",
    "\n",
    "    if name in person:\n",
    "        temp = pd.read_csv(file, delimiter = \" \", header = None)\n",
    "        print(person, ' is read', end = \"\\t\")\n",
    "        \n",
    "        if 2 in temp[max(temp.columns)].unique():\n",
    "            print(\"Adding {} to dataset\".format(person), end = \"\\t\")\n",
    "            temp.columns = [\n",
    "                                'time',\n",
    "                                'A_F', 'A_V', 'A_L',\n",
    "                                'L_F', 'L_V', 'L_L',\n",
    "                                'T_F', 'T_V', 'T_L',\n",
    "                                'Action'                           \n",
    "                                ]\n",
    "            \n",
    "            temp = label_prefog(temp, window_length).reset_index(drop = True)\n",
    "            temp['name'] = name\n",
    "            print(\"{} is labelled\".format(person))\n",
    "            dataset = pd.concat([dataset, temp],axis = 0)\n",
    "        print('')\n",
    "\n",
    "        dataset.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "        to_name = first_processing_path + \"/win_\" + name + \".csv\"\n",
    "    # 存入/raw_labelled中\n",
    "\n",
    "    if not dataset.empty:\n",
    "        dataset.to_csv(to_name, index = False)\n",
    "\n",
    "del last_name, name, person, people, dataset, temp, to_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(act,window_length,dataframe):\n",
    "\n",
    "  indices = list(dataframe[dataframe.Action == act].index)\n",
    "  time = []\n",
    "  time_count = 0\n",
    "  for j in indices:\n",
    "    time.append(dataframe.loc[j, 'time'])\n",
    "\n",
    "\n",
    "  # indices記錄所有Action==act的index\n",
    "  groups = [] # 用來暫存一組(同action)資料的, 型態是[][]\n",
    "  temp = [] # 用來暫存一行資料的\n",
    "  group_count = 0\n",
    "  for i in range(len(indices)):\n",
    "    if i == len(indices)-1:\n",
    "      temp.append(indices[i])\n",
    "      groups.append(temp)\n",
    "      temp = []\n",
    "      break # 如果i已經來到最後的話就break\n",
    "    temp.append(indices[i])\n",
    "    #time_count = time_count + 1\n",
    "    if time[i+1]-16 > time[i]: #如果下個index不是連續的話, 就將前面這些存成第一組\n",
    "      group_count+=1\n",
    "      #time_count = time_count + 1\n",
    "      groups.append(temp)\n",
    "      temp = []\n",
    "\n",
    "  #print(groups)\n",
    "\n",
    "  fs = 64\n",
    "  # window_length = 1\n",
    "  # window_length = int(window_length*fs)\n",
    "\n",
    "  final_dataframe = pd.DataFrame()\n",
    "  sumOfAct=0\n",
    "\n",
    "  for i in groups: # group[][]的每一行i\n",
    "    required = math.floor(len(i)/int(window_length/2))\n",
    "\n",
    "    \n",
    "    sumOfAct= sumOfAct+required\n",
    "\n",
    "    req_index = i[0:(required*int(window_length/2))]\n",
    "\n",
    "    #print(req_index)\n",
    "    # concat([要結合的data集合], axis=0是方向為直的)\n",
    "    final_dataframe = pd.concat([final_dataframe,dataframe.iloc[req_index,:]],axis = 0)\n",
    "  \n",
    "  \n",
    "\n",
    "  return final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in patients:\n",
    "\n",
    "  name = first_processing_path + \"/win_\"+ patient +\".csv\"\n",
    "\n",
    "  if os.path.isfile(name):\n",
    "    dataset = pd.read_csv(name)\n",
    "\n",
    "    activities = []\n",
    "    # print(patient)\n",
    "    for act in range(3):\n",
    "      activities.append(create_window(act,window_length,dataset))\n",
    "    to_write = pd.concat(activities,axis = 0)\n",
    "    to_path = second_processing_path + \"/windowed_\" + patient + \".csv\"\n",
    "    to_write.to_csv(to_path,index = False)\n",
    "\n",
    "del name, to_path, to_write, dataset, activities, patient, act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 將 train test 以 patients 區分\n",
    "\n",
    "train_patients_dataset = pd.DataFrame()\n",
    "test_patients_dataset = pd.DataFrame()\n",
    "\n",
    "for patient in patients:\n",
    "    name = second_processing_path + \"\\\\windowed_\" + patient + \".csv\"\n",
    "\n",
    "    if not os.path.isfile(name):\n",
    "        continue\n",
    "    \n",
    "    dataset = pd.read_csv(name)\n",
    "\n",
    "    if patient == test_patients[0]:\n",
    "        test_patients_dataset = test_patients_dataset.append(dataset)\n",
    "    else:    \n",
    "        train_patients_dataset = train_patients_dataset.append(dataset)\n",
    "\n",
    "to_path = final_dataset_path + \"/not_windowed_train.csv\"\n",
    "train_patients_dataset.to_csv(to_path, index=False)\n",
    "\n",
    "to_path = final_dataset_path + \"/not_windowed_test.csv\"\n",
    "test_patients_dataset.to_csv(to_path, index=False)\n",
    "\n",
    "del name, dataset, patient, test_patients_dataset, train_patients_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + \"/dataset/not_windowed_train.csv\"\n",
    "dataset = pd.read_csv(data_path)\n",
    "\n",
    "import math\n",
    "\n",
    "activities = []\n",
    "for act in range(3):\n",
    "    activities.append(create_window(act,window_length,dataset))\n",
    "to_write = pd.concat(activities, axis = 0)\n",
    "to_path = os.getcwd() + \"/dataset/total_train.csv\"\n",
    "to_write.to_csv(to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + \"/dataset/not_windowed_test.csv\"\n",
    "dataset = pd.read_csv(data_path)\n",
    "\n",
    "import math\n",
    "\n",
    "activities = []\n",
    "for act in range(3):\n",
    "    activities.append(create_window(act,window_length,dataset))\n",
    "to_write = pd.concat(activities, axis = 0)\n",
    "to_path = os.getcwd() + \"/dataset/total_test.csv\"\n",
    "to_write.to_csv(to_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8986fb416174cc2474d1ce69838b7b56508ac61c47a66825c7584556038319d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('HighHeelWhatever')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
